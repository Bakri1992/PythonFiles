{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Importing a CSV file into a postgres database:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Steps:\n",
    "- Import the csv file into a pandas df.\n",
    "- Clean the table name and remove all extra symbols.\n",
    "- clean the column headers and remove all extra symbols, spaces, capital letters.\n",
    "- write the create table SQL statement\n",
    "- Import the data into the Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all needed libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as numpy\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Find CSV files in directory:**\n",
    "- Find the cvs files in my current working directory.\n",
    "- Isolate only the csv files.\n",
    "- Make a new directory.\n",
    "- Move the CSV files in the new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in my current working directory\n",
    "os.listdir(os.getcwd())\n",
    "\n",
    "# Lets isolate the csv files from my folder\n",
    "csv_files=[]\n",
    "for file in os.listdir(os.getcwd()):\n",
    "    if file.endswith(\".csv\"):\n",
    "        csv_files.append(file)\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new directory\n",
    "datasets_file=input(\"Please enter the folder to save CSV file?\")\n",
    "\n",
    "# Create the bash or cmd command to make a new directory\n",
    "mkdir= \"mkdir {}\".format(datasets_file)\n",
    "os.system(mkdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the csv files in the new directory\n",
    "for csv in csv_files:\n",
    "    mv_file=\"move {} {}\".format(csv,datasets_file)\n",
    "    # mv_file=\"mv {} {}\".format(csv,dataset_dir) shell command linux\n",
    "    os.system(mv_file)\n",
    "    print(mv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Create the Pandas df from the CSV files:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here a very good way to store dataframes in dictionary:\n",
    "data_path=os.getcwd()+ \"\\\\\" +datasets_file+\"\\\\\"\n",
    "# print(data_path)\n",
    "df={}\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df[file]=pd.read_csv(data_path+file)\n",
    "    except UnicodeDecodeError:\n",
    "        df[file]=pd.read_csv(data_path+file,encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>minimum_age</th>\n",
       "      <th>maximum_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>geo_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>female</td>\n",
       "      <td>61747</td>\n",
       "      <td>8600000US61747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>male</td>\n",
       "      <td>64120</td>\n",
       "      <td>8600000US64120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1389</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>male</td>\n",
       "      <td>95117</td>\n",
       "      <td>8600000US95117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231</td>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>female</td>\n",
       "      <td>74074</td>\n",
       "      <td>8600000US74074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>female</td>\n",
       "      <td>58042</td>\n",
       "      <td>8600000US58042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622826</th>\n",
       "      <td>66</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>female</td>\n",
       "      <td>28640</td>\n",
       "      <td>8600000US28640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622827</th>\n",
       "      <td>791</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>male</td>\n",
       "      <td>98604</td>\n",
       "      <td>8600000US98604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622828</th>\n",
       "      <td>55</td>\n",
       "      <td>55.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>female</td>\n",
       "      <td>29545</td>\n",
       "      <td>8600000US29545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622829</th>\n",
       "      <td>10</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>female</td>\n",
       "      <td>45319</td>\n",
       "      <td>8600000US45319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622830</th>\n",
       "      <td>65</td>\n",
       "      <td>35.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>female</td>\n",
       "      <td>71032</td>\n",
       "      <td>8600000US71032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1622831 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         population  minimum_age  maximum_age  gender  zipcode          geo_id\n",
       "0                50         30.0         34.0  female    61747  8600000US61747\n",
       "1                 5         85.0          NaN    male    64120  8600000US64120\n",
       "2              1389         30.0         34.0    male    95117  8600000US95117\n",
       "3               231         60.0         61.0  female    74074  8600000US74074\n",
       "4                56          0.0          4.0  female    58042  8600000US58042\n",
       "...             ...          ...          ...     ...      ...             ...\n",
       "1622826          66         15.0         17.0  female    28640  8600000US28640\n",
       "1622827         791         25.0         29.0    male    98604  8600000US98604\n",
       "1622828          55         55.0         59.0  female    29545  8600000US29545\n",
       "1622829          10         25.0         29.0  female    45319  8600000US45319\n",
       "1622830          65         35.0         39.0  female    71032  8600000US71032\n",
       "\n",
       "[1622831 rows x 6 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"population_by_zip_2010.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacment dictionary that maps pandas dtypes to sql dtypes\n",
    "replacments={\n",
    "    \"object\":\"varchar\",\n",
    "    \"float64\":\"float\",\n",
    "    \"int64\":\"int\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Clean Table names and Column names :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in csv_files:\n",
    "    dataframe=df[k]    \n",
    "    clean_table_name=k.lower().replace(\" \",\"_\").replace(\"?\",\"\") \\\n",
    "        .replace(\"-\",\"_\").replace( \"/\" ,\"_\").replace(\"\\\\\",\"_\") \\\n",
    "        .replace(\"%\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"$\",\"\")\n",
    "    # remove .csv extension from clean_table_name\n",
    "    table_name=\"{}\".format(clean_table_name.split(\".\")[0])\n",
    "    print(table_name)\n",
    "    # Clean the column name\n",
    "    dataframe.columns=[x.lower().replace(\" \",\"_\").replace(\"?\",\"\") \\\n",
    "        .replace(\"-\",\"_\").replace( \"/\" ,\"_\").replace(\"\\\\\",\"_\") \\\n",
    "        .replace(\"%\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"$\",\"\")\n",
    "        for x in dataframe.columns      \n",
    "        ]\n",
    "    print(dataframe.columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String of creating table schema\n",
    "# table schema\n",
    "col_str=\", \".join([\"{} {}\".format(c,d) for (c,d) in zip(dataframe.columns, \\\n",
    "                                        dataframe.dtypes.replace(replacments))])\n",
    "print(col_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Adding the Database connection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a database connection\n",
    "host=\"localhost\"\n",
    "database=\"mydb\"\n",
    "user=\"postgres\"\n",
    "password=\"password\"\n",
    "port=5432\n",
    "\n",
    "conn_string= \"host=%s database=%s user=%s password=%s port=%s\" % \\\n",
    "                (host,database,user,password,port )\n",
    "conn=psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "print(\"connected to database successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop table with the same name\n",
    "cur.execute(\"DROP TABLE IF EXISTS %s\" % (table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table\n",
    "cur.execute(\"create table %s (%s) \"% (table_name,col_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the Dataframe in csv file a:\n",
    "dataframe.to_csv(k,header=dataframe.columns,index=False,encoding=\"utf-8\")\n",
    "# open the csv file , save it as an object\n",
    "my_file=open(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to upload the csv file into the database\n",
    "# We can use the copy method\n",
    "SQL_STATEMENT=\"\"\"\n",
    "Copy %s FROM STDIN WITH\n",
    "    CSV\n",
    "    HEADER\n",
    "    DELIMETER AS \",\"\n",
    "\"\"\"\n",
    "cur.copy_expert(sql=SQL_STATEMENT % table_name,file=my_file)\n",
    "print(\"File copied to database!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grant access to users\n",
    "cur.execute(f\"GRANT SELECT ON TABLE {table_name} TO PUBLIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full\n",
    "for k in csv_files:\n",
    "    dataframe=df[k]    \n",
    "    clean_table_name=k.lower().replace(\" \",\"_\").replace(\"?\",\"\") \\\n",
    "        .replace(\"-\",\"_\").replace( \"/\" ,\"_\").replace(\"\\\\\",\"_\") \\\n",
    "        .replace(\"%\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"$\",\"\")\n",
    "    # remove .csv extension from clean_table_name\n",
    "    table_name=\"{}\".format(clean_table_name.split(\".\")[0])\n",
    "    print(table_name)\n",
    "    # Clean the column name\n",
    "    dataframe.columns=[x.lower().replace(\" \",\"_\").replace(\"?\",\"\") \\\n",
    "        .replace(\"-\",\"_\").replace( \"/\" ,\"_\").replace(\"\\\\\",\"_\") \\\n",
    "        .replace(\"%\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"$\",\"\")\n",
    "        for x in dataframe.columns      \n",
    "        ]\n",
    "    print(dataframe.columns)\n",
    "    \n",
    "    # table schema\n",
    "    col_str=\", \".join([\"{} {}\".format(c,d) for (c,d) in zip(dataframe.columns, \\\n",
    "                                        dataframe.dtypes.replace(replacments))])\n",
    "    print(col_str)\n",
    "    \n",
    "    \n",
    "    # connecting to our database\n",
    "    # open a database connection\n",
    "    host=\"localhost\"\n",
    "    database=\"mydb\" \n",
    "    user=\"postgres\"\n",
    "    password=\"admin\"\n",
    "    port=5432\n",
    "\n",
    "    conn_string= \"host=%s dbname=%s user=%s password=%s port=%s\" % \\\n",
    "                    (host,database,user,password,port )\n",
    "    conn=psycopg2.connect(conn_string)\n",
    "    cur=conn.cursor()\n",
    "    print(\"connected to database successfully\")\n",
    "    cur.execute(\"DROP TABLE IF EXISTS %s\" % (table_name))\n",
    "    # Create table\n",
    "    cur.execute(\"create table %s (%s) \"% (table_name,col_str))\n",
    "    print(\"{} was created successfully!\".format(table_name))\n",
    "    \n",
    "    # Saving the Dataframe in csv file:\n",
    "    dataframe.to_csv(k,header=dataframe.columns,index=False,encoding=\"utf-8\")\n",
    "    # k is here my new file name\n",
    "    my_file=open(k)\n",
    "    print(\"File is open as object...\")\n",
    "    SQL_STATEMENT=\"\"\"\n",
    "        Copy %s FROM STDIN WITH\n",
    "        CSV\n",
    "        HEADER\n",
    "        DELIMITER AS ','\n",
    "        \"\"\"\n",
    "    cur.copy_expert(sql=SQL_STATEMENT % table_name,file=my_file)\n",
    "    print(\"File copied to database!\")       \n",
    "    \n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yosue__f'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=\"Yosue  f%?\"\n",
    "clean_table_name=n.lower().replace(\" \",\"-\").replace(\"?\",\"\") \\\n",
    "        .replace(\"-\",\"_\").replace( \"/\" ,\"_\").replace(\"\\\\\",\"_\") \\\n",
    "        .replace(\"%\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"$\",\"\")\n",
    "clean_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
