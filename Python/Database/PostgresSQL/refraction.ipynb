{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter the csv files into a list\n",
    "def csv_files():\n",
    "    csv_files=[]\n",
    "    for file in os.listdir(os.getcwd()):\n",
    "        if file.endswith(\".csv\"):\n",
    "            csv_files.append(file)\n",
    "    return csv_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_dataset_directory(csv_files,dataset_dir):\n",
    "    # Make directory\n",
    "    mkdir=f\"mkdir {dataset_dir}\"\n",
    "    os.system(mkdir)\n",
    "    \n",
    "    # Move csv files to directory\n",
    "    for csv in csv_files:\n",
    "        mv_file=f\"move {csv} {dataset_dir}\"\n",
    "        os.system(mv_file)\n",
    "        print(mv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main \n",
    "dataset_dir=input(\"Enter the folder name to create?\")\n",
    "csv_files=csv_files()\n",
    "configure_dataset_directory(csv_files,dataset_dir)\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(csv_files,dataset_dir):\n",
    "    # Path to csv files\n",
    "    data_path=os.getcwd()+\"\\\\\"+dataset_dir\n",
    "    # loop throw the csv files and create dataframe\n",
    "    df={}\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df[file]=pd.read_csv(os.path.join(data_path,file))\n",
    "        except UnicodeDecodeError:\n",
    "            df[file]=pd.read_csv(os.path.join(data_path,file),encoding=\"ISO-8859-1\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table_name(filename):\n",
    "    clean_table_name=filename.lower().replace(\" \",\"_\").replace(\"?\",\"\") \\\n",
    "        .replace(\"-\",\"_\").replace( \"/\" ,\"_\").replace(\"\\\\\",\"_\") \\\n",
    "        .replace(\"%\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"$\",\"\")\n",
    "    table_name=\"{}\".format(clean_table_name.split(\".\")[0])\n",
    "    return clean_table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_colname(dataframe):\n",
    "    dataframe.columns=[x.lower().replace(\" \",\"_\").replace(\"?\",\"\") \\\n",
    "        .replace(\"-\",\"_\").replace( \"/\" ,\"_\").replace(\"\\\\\",\"_\") \\\n",
    "        .replace(\"%\",\"\").replace(\")\",\"\").replace(\"(\",\"\").replace(\"$\",\"\")\n",
    "        for x in dataframe.columns      \n",
    "        ]\n",
    "    # replacment dictionary that maps pandas dtypes to sql dtypes\n",
    "    replacments={\n",
    "        \"object\":\"varchar\",\n",
    "        \"float64\":\"float\",\n",
    "        \"int64\":\"int\"\n",
    "        }\n",
    "    col_str=\", \".join([\"{} {}\".format(c,d) for (c,d) in zip(dataframe.columns, \\\n",
    "                                        dataframe.dtypes.replace(replacments))])\n",
    "    \n",
    "    return col_str, dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_db(host, dbname, user, password, tbl_name, col_str, file, dataframe, dataframe_columns):\n",
    "\n",
    "    conn_string = \"host=%s dbname=%s user=%s password=%s\" % (host, dbname, user, password)\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    cursor = conn.cursor()\n",
    "    print('opened database successfully')\n",
    "    \n",
    "    #drop table with same name\n",
    "    cursor.execute(\"drop table if exists %s;\" % (tbl_name))\n",
    "\n",
    "    #create table\n",
    "    cursor.execute(\"create table %s (%s);\" % (tbl_name, col_str))\n",
    "    print('{0} was created successfully'.format(tbl_name)) \n",
    "    \n",
    "    #insert values to table\n",
    "\n",
    "    #save df to csv\n",
    "    dataframe.to_csv(file, header=dataframe_columns, index=False, encoding='utf-8')\n",
    "\n",
    "    #open the csv file, save it as an object\n",
    "    my_file = open(file)\n",
    "    print('file opened in memory')\n",
    "    \n",
    "    #upload to db\n",
    "    SQL_STATEMENT = \"\"\"\n",
    "    COPY %s FROM STDIN WITH\n",
    "        CSV\n",
    "        HEADER\n",
    "        DELIMITER AS ','\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.copy_expert(sql=SQL_STATEMENT % tbl_name, file=my_file)\n",
    "    print('file copied to db')\n",
    "    \n",
    "    cursor.execute(\"grant select on table %s to public\" % tbl_name)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print('table {0} imported to db completed'.format(tbl_name))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main \n",
    "\n",
    "#settings\n",
    "dataset_dir = 'datasets'\n",
    "\n",
    "#db settings\n",
    "host = 'add db ip'\n",
    "dbname = 'add db name'\n",
    "user = 'add db username'\n",
    "password = 'add db pwd'\n",
    "\n",
    "#configure environment and create main df\n",
    "csv_files = csv_files()\n",
    "configure_dataset_directory(csv_files, dataset_dir)\n",
    "df = create_df(dataset_dir, csv_files)\n",
    "\n",
    "for k in csv_files:\n",
    "\n",
    "    #call dataframe\n",
    "    dataframe = df[k]\n",
    "\n",
    "    #clean table name\n",
    "    tbl_name = clean_table_name(k)\n",
    "    \n",
    "    #clean column names\n",
    "    col_str, dataframe.columns = clean_colname(dataframe)\n",
    "    \n",
    "    #upload data to db   \n",
    "    upload_to_db(host, \n",
    "                 dbname, \n",
    "                 user, \n",
    "                 password, \n",
    "                 tbl_name, \n",
    "                 col_str, \n",
    "                 file=k, \n",
    "                 dataframe=dataframe, \n",
    "                 dataframe_columns=dataframe.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
